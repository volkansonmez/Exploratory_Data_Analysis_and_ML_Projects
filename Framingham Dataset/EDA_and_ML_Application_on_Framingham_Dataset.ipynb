{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notebook by [Volkan Sonmez] (http://www.pythonicfool.com/)  \n",
    "### Framingham Dataset is analyzed with matplotlib.image library \n",
    "### A One-Layer-NN and KNN algorithms are written from scratch with numpy. The models are trained and tested. For checking the performace and accuracy of our models with a third party, Sklearn's Logistic Regression model is run on this dataset. A Three-Layer_NN is also created with pytorch to see if/how model's complexity show difference in test accuracy. \n",
    "\n",
    "\n",
    "####  https://github.com/volkansonmez/Exploratory_Data_Analysis_and_ML_Projects\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of contents\n",
    "\n",
    "1. [Introduction](#Introduction)\n",
    "\n",
    "2. [License](#License)\n",
    "\n",
    "3. [EDA and Building ML Model](#EDA_and_Building_ML_Model)\n",
    "\n",
    "4. [Conclusion](#Conclusion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "[[ go back to the top ]](#Table-of-contents)\n",
    "    \n",
    "Raw framingham.csv dataset is downloaded from Kaggle. The dataset is cleaned, the feature scoring analysis and pruning is done. 3 different ML algorithms are applied for logistic regression analysis. There are clean instructions to follow each step for the beginners."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## License\n",
    "\n",
    "[[ go back to the top ]](#Table-of-contents)\n",
    "\n",
    "Please see the [repository README file](https://github.com/volkansonmez/Exploratory_Data_Analysis_and_ML_Projects) \n",
    "for the licenses and usage terms for the instructional material and code in this notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDA_and_Building_ML_Model\n",
    "\n",
    "[[ go back to the top ]](#Table-of-contents)\n",
    "\n",
    "How to do it: \n",
    "\n",
    "After cleaning the dataset, drop the NA values, check the feature scores with chi2 test. Any feature score below 10 is dismissed in this notebook but you are welcome to change your min. feature score value. Since it is a logistic regression problem, write the sigmoid function and its derivative to be used later in NN. \n",
    "\n",
    "Create a one layer neural network from scratch (not with pytorch but with numpy only) and train it. Do a grid search for optimimum iterations, learning rate, and learning rate decay for obtaining the best test accuracy. \n",
    "\n",
    "Write KNN from scratch to see if it is possible to beat the deep learning method in test accuracy. Tweak the KNN just for this problem to adapt it to the data since it is mostly composed of \"0\" values in the target column (this is not recommended outside of this particular problem)\n",
    "\n",
    "Compare your results of sklearn's logistic regression algorithm. Show your results in confusion matrix.\n",
    "\n",
    "BONUS: Create a more complex NN model with pytorch sequential (a model with few layers) to see if increasing the model's complexity will help reaching better accuracy. \n",
    "\n",
    "This data is specifically selected for showing students that sometimes the data is not sufficient to reach a good accuracy regardless of any machine learning algorithm used. Increasing complexity sometimes is not necessary. If your data is good, sufficient, and not too noisy, you can get good results.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4238\n",
      "   male  age  education  currentSmoker  cigsPerDay  BPMeds  prevalentStroke  \\\n",
      "0     1   39        4.0              0         0.0     0.0                0   \n",
      "1     0   46        2.0              0         0.0     0.0                0   \n",
      "2     1   48        1.0              1        20.0     0.0                0   \n",
      "3     0   61        3.0              1        30.0     0.0                0   \n",
      "4     0   46        3.0              1        23.0     0.0                0   \n",
      "\n",
      "   prevalentHyp  diabetes  totChol  sysBP  diaBP    BMI  heartRate  glucose  \\\n",
      "0             0         0    195.0  106.0   70.0  26.97       80.0     77.0   \n",
      "1             0         0    250.0  121.0   81.0  28.73       95.0     76.0   \n",
      "2             0         0    245.0  127.5   80.0  25.34       75.0     70.0   \n",
      "3             1         0    225.0  150.0   95.0  28.58       65.0    103.0   \n",
      "4             0         0    285.0  130.0   84.0  23.10       85.0     85.0   \n",
      "\n",
      "   TenYearCHD  \n",
      "0           0  \n",
      "1           0  \n",
      "2           0  \n",
      "3           1  \n",
      "4           0  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "male                 0\n",
       "age                  0\n",
       "education          105\n",
       "currentSmoker        0\n",
       "cigsPerDay          29\n",
       "BPMeds              53\n",
       "prevalentStroke      0\n",
       "prevalentHyp         0\n",
       "diabetes             0\n",
       "totChol             50\n",
       "sysBP                0\n",
       "diaBP                0\n",
       "BMI                 19\n",
       "heartRate            1\n",
       "glucose            388\n",
       "TenYearCHD           0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "%matplotlib inline\n",
    "\n",
    "# Import the dataset\n",
    "framingham_data = pd.read_csv(\"framingham.csv\") \n",
    "print(len(framingham_data))\n",
    "print(framingham_data[:5]) # visualize the first 5 instances of the dataset\n",
    "\n",
    "df = framingham_data # make a copy of the data to play with it\n",
    "df.isna().sum()\n",
    "\n",
    "# Unmark the below lines to check for duplicates if needed\n",
    "# duplicate_df = df[df.duplicated()]\n",
    "# print(duplicate_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3656, 16)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "male               0\n",
       "age                0\n",
       "education          0\n",
       "currentSmoker      0\n",
       "cigsPerDay         0\n",
       "BPMeds             0\n",
       "prevalentStroke    0\n",
       "prevalentHyp       0\n",
       "diabetes           0\n",
       "totChol            0\n",
       "sysBP              0\n",
       "diaBP              0\n",
       "BMI                0\n",
       "heartRate          0\n",
       "glucose            0\n",
       "TenYearCHD         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop the NaN values\n",
    "df = df.dropna()\n",
    "print(df.shape)\n",
    "# Check if there are any NaN values left in the dataset. \n",
    "df.isna().sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    3099\n",
       "1     557\n",
       "Name: TenYearCHD, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# View the number of 1's and 0's in the dataset\n",
    "df.TenYearCHD.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3656, 16)\n",
      "              Specs       Score\n",
      "0              male   17.120430\n",
      "1               age  295.507761\n",
      "2         education    7.679797\n",
      "3     currentSmoker    0.686913\n",
      "4        cigsPerDay  156.567318\n",
      "5            BPMeds   28.153003\n",
      "6   prevalentStroke    8.497823\n",
      "7      prevalentHyp   82.967184\n",
      "8          diabetes   31.027987\n",
      "9           totChol  249.153078\n",
      "10            sysBP  669.506552\n",
      "11            diaBP  142.878574\n",
      "12              BMI   15.730717\n",
      "13        heartRate    2.919062\n",
      "14          glucose  379.583137\n",
      "(3656, 16)\n"
     ]
    }
   ],
   "source": [
    "# Check the feature scores \n",
    "print(df.shape)# the total number of attributes including the label\n",
    "\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "\n",
    "X = df.iloc[:,:-1]   # data\n",
    "y = df.iloc[:,-1]    # labels\n",
    "\n",
    "# check the scores\n",
    "bestfeatures = SelectKBest(score_func=chi2, k= \"all\")\n",
    "fit = bestfeatures.fit(X,y)\n",
    "dfscores = pd.DataFrame(fit.scores_)\n",
    "dfcolumns = pd.DataFrame(X.columns)\n",
    "\n",
    "# concat two dataframes for better visualization \n",
    "featureScores = pd.concat([dfcolumns, dfscores], axis=1, sort= False)\n",
    "featureScores.columns = ['Specs','Score']  \n",
    "print(featureScores)\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the unnecessary columns \n",
    "df = df.drop(['currentSmoker','education', 'heartRate', 'prevalentStroke'] ,axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3656, 12)\n",
      "(3656, 11) (3656,)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>male</th>\n",
       "      <th>age</th>\n",
       "      <th>cigsPerDay</th>\n",
       "      <th>BPMeds</th>\n",
       "      <th>prevalentHyp</th>\n",
       "      <th>diabetes</th>\n",
       "      <th>totChol</th>\n",
       "      <th>sysBP</th>\n",
       "      <th>diaBP</th>\n",
       "      <th>BMI</th>\n",
       "      <th>glucose</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>3656.000000</td>\n",
       "      <td>3656.000000</td>\n",
       "      <td>3656.000000</td>\n",
       "      <td>3656.000000</td>\n",
       "      <td>3656.000000</td>\n",
       "      <td>3656.000000</td>\n",
       "      <td>3656.000000</td>\n",
       "      <td>3656.000000</td>\n",
       "      <td>3656.000000</td>\n",
       "      <td>3656.000000</td>\n",
       "      <td>3656.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.443654</td>\n",
       "      <td>0.462038</td>\n",
       "      <td>0.128888</td>\n",
       "      <td>0.030361</td>\n",
       "      <td>0.311543</td>\n",
       "      <td>0.027079</td>\n",
       "      <td>0.254360</td>\n",
       "      <td>0.231054</td>\n",
       "      <td>0.369440</td>\n",
       "      <td>0.248284</td>\n",
       "      <td>0.118238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.496883</td>\n",
       "      <td>0.225293</td>\n",
       "      <td>0.170270</td>\n",
       "      <td>0.171602</td>\n",
       "      <td>0.463187</td>\n",
       "      <td>0.162335</td>\n",
       "      <td>0.090547</td>\n",
       "      <td>0.104456</td>\n",
       "      <td>0.126718</td>\n",
       "      <td>0.098544</td>\n",
       "      <td>0.067543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.263158</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.190965</td>\n",
       "      <td>0.158392</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.182744</td>\n",
       "      <td>0.087571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.447368</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.248460</td>\n",
       "      <td>0.210402</td>\n",
       "      <td>0.359788</td>\n",
       "      <td>0.238488</td>\n",
       "      <td>0.107345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.631579</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.308522</td>\n",
       "      <td>0.286052</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.302957</td>\n",
       "      <td>0.132768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              male          age   cigsPerDay       BPMeds  prevalentHyp  \\\n",
       "count  3656.000000  3656.000000  3656.000000  3656.000000   3656.000000   \n",
       "mean      0.443654     0.462038     0.128888     0.030361      0.311543   \n",
       "std       0.496883     0.225293     0.170270     0.171602      0.463187   \n",
       "min       0.000000     0.000000     0.000000     0.000000      0.000000   \n",
       "25%       0.000000     0.263158     0.000000     0.000000      0.000000   \n",
       "50%       0.000000     0.447368     0.000000     0.000000      0.000000   \n",
       "75%       1.000000     0.631579     0.285714     0.000000      1.000000   \n",
       "max       1.000000     1.000000     1.000000     1.000000      1.000000   \n",
       "\n",
       "          diabetes      totChol        sysBP        diaBP          BMI  \\\n",
       "count  3656.000000  3656.000000  3656.000000  3656.000000  3656.000000   \n",
       "mean      0.027079     0.254360     0.231054     0.369440     0.248284   \n",
       "std       0.162335     0.090547     0.104456     0.126718     0.098544   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       0.000000     0.190965     0.158392     0.285714     0.182744   \n",
       "50%       0.000000     0.248460     0.210402     0.359788     0.238488   \n",
       "75%       0.000000     0.308522     0.286052     0.444444     0.302957   \n",
       "max       1.000000     1.000000     1.000000     1.000000     1.000000   \n",
       "\n",
       "           glucose  \n",
       "count  3656.000000  \n",
       "mean      0.118238  \n",
       "std       0.067543  \n",
       "min       0.000000  \n",
       "25%       0.087571  \n",
       "50%       0.107345  \n",
       "75%       0.132768  \n",
       "max       1.000000  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df.iloc[:,:-1]   # data\n",
    "y = df.iloc[:,-1]    # labels\n",
    "\n",
    "# normalize the dataset\n",
    "print(df.shape)\n",
    "print(X.shape, y.shape)\n",
    "\n",
    "# Rescale the values in the attributes between 0 and 1\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler(feature_range=(0,1)) \n",
    "X_scaled = pd.DataFrame(scaler.fit_transform(X), columns= X.columns)\n",
    "\n",
    "# view the data description\n",
    "X_scaled.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.         0.52631579 0.21428571 0.         0.         0.\n",
      " 0.15811088 0.16312057 0.33862434 0.21643238 0.13559322]\n",
      "[0.         0.63157895 0.42857143 0.         0.         0.\n",
      " 0.35934292 0.18676123 0.23280423 0.07464857 0.15819209]\n",
      "labels: [[0]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [0]] [[0]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [0]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(556, 1)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Turn the dataframe into numpy array, shuffle the data, do the test and train split, reshape the labels\n",
    "\n",
    "dataset = np.array(X_scaled)\n",
    "y = np.array(y)\n",
    "\n",
    "# shuffle the data, separate data to test and train sets\n",
    "np.random.seed(0)\n",
    "shuffled_indices = np.random.permutation(len(y))\n",
    "shuffled_dataset = dataset[shuffled_indices]\n",
    "\n",
    "# assign the test and train data manually\n",
    "train_set = shuffled_dataset[:3100]\n",
    "test_set = shuffled_dataset[3100:]\n",
    "print(train_set[0])\n",
    "print(test_set[0])\n",
    "\n",
    "# assign the test and train labels\n",
    "y = y[:, np.newaxis]\n",
    "shuffled_labels = y[shuffled_indices]\n",
    "train_label = shuffled_labels[:3100]\n",
    "test_label = shuffled_labels[3100:]\n",
    "print('labels:', train_label[:5], test_label[:5]) # visualize the labels\n",
    "test_label.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    3099\n",
      "1     557\n",
      "Name: TenYearCHD, dtype: int64\n",
      "0.15235229759299782 0.8476477024070022\n"
     ]
    }
   ],
   "source": [
    "# Before moving on with a classic ML algorithm to do logistic regression, revisit the label score rates\n",
    "target_count = df.TenYearCHD.value_counts()\n",
    "print(target_count)\n",
    "# if accuracy was going to be evaluated based on sensitivity and specificity these are the tp and tn amounts below:\n",
    "tp_rate = 557/len(df)\n",
    "tn_rate = 3099/len(df)\n",
    "print(tp_rate , tn_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fbdbaf12250>]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Write and test the sigmoid function \n",
    "def sigmoid(x):\n",
    "    return 1/(1+np.exp(-x))\n",
    "\n",
    "def sigmoid_p(x):\n",
    "    return sigmoid(x) * (1-sigmoid(x))\n",
    "\n",
    "# Visualize the sigmoid function and its derivative\n",
    "X = np.linspace(-5, 5, 100)\n",
    "plt.plot(X, sigmoid(X), c=\"b\") # sigmoid in blue\n",
    "plt.plot(X, sigmoid_p(X), c=\"r\") # sigmoid_p in red"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best hyper-parameters: 2000 0.1 0.98\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] [0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0]\n",
      "accuracy 0.8776978417266187\n",
      "487 0 68 1\n",
      "0.8521739130434782\n"
     ]
    }
   ],
   "source": [
    "# Write a one layer NN and train the network, test it and analyze the result with confusion matrix\n",
    "# Analyze the accuracy with a grid search on all hyperparameters\n",
    "\n",
    "import numpy as np\n",
    "class Neural_Network():\n",
    "    def __init__(self):\n",
    "        # set the network parameters\n",
    "        self.inputSize = 11 # there are 11 attributes for each input. \n",
    "        self.outputSize = 1 # the output will be a single value\n",
    "\n",
    "        # set the weights\n",
    "        self.W = 0.01 * np.random.randn(self.inputSize, self.outputSize)\n",
    "        self.b = np.zeros([1, self.outputSize])\n",
    "        self.lr = 0.01\n",
    "        \n",
    "    def forward(self, input_data):\n",
    "        # forward propagation\n",
    "        self.z = np.dot(input_data, self.W) + self.b # dot product of X (input) and weights\n",
    "        self.o = self.sigmoid(self.z) # fit the logit into the activation function\n",
    "        return self.o # return scores\n",
    "\n",
    "    def sigmoid(self, s):\n",
    "        # activation function\n",
    "        return 1/(1+np.exp(-s))\n",
    "\n",
    "    def dsigmoid(self, s):\n",
    "        # derivative of sigmoid\n",
    "        return s * (1 - s)\n",
    "\n",
    "    def backward(self, input_data, label):\n",
    "        # backward propagation \n",
    "        #self.do = self.o - label # (since the loss function used is: log loss)\n",
    "        self.dz = self.o - label\n",
    "        self.db = self.dz \n",
    "        self.dW = np.dot(input_data.T , self.dz)\n",
    "\n",
    "        # vanilla update of the weights and biases\n",
    "        self.b -=  self.lr * self.db\n",
    "        self.W -=  self.lr * self.dW \n",
    "    \n",
    "    # all parameters here are LIST of numbers to do grid search to optimize the results  \n",
    "    def train(self, train_set, test_set, test_label, train_label, iteration_i, lr, decay): \n",
    "        NN.lr = lr\n",
    "        # train the network \n",
    "        for i in range(iteration_i):\n",
    "            ri = np.random.randint(len(train_set)) # random index\n",
    "            rd = train_set[ri] # instance at the random index picked\n",
    "            rd = rd[np.newaxis,:] # reshape the instance to 2D. (1,12)\n",
    "            y = train_label[ri] # label of the random instance picked\n",
    "            self.forward(rd)\n",
    "            self.backward(rd, y)\n",
    "            if (i % 100) == 299:\n",
    "                NN.lr *= decay \n",
    "        # done with the training, test the test set data on the trained network\n",
    "        pred_list = [] # store the predictions in this list\n",
    "        for j in range(len(test_set)): # for each item in the test set, make predictions and check the accuracy\n",
    "            test_data = test_set[j] \n",
    "            fwd_prop = NN.forward(test_data)\n",
    "            predict_value = float(fwd_prop)\n",
    "            if predict_value < 0.5:\n",
    "                prediction = 0\n",
    "            else:\n",
    "                prediction = 1\n",
    "            pred_list.append(prediction)\n",
    "        # pass the predictins to confusion matrix\n",
    "        tn, fp, fn, tp = confusion_matrix(test_label, pred_list).ravel() # actual labels compared with predictions \n",
    "        specificity_and_sensitivity_average = (0.85* tn/(tn+fp) + 0.15* tp/(tp+fn)) # weighted average \n",
    "        return specificity_and_sensitivity_average, pred_list\n",
    "\n",
    "    \n",
    "#     def saveWeights(self): # this saves a text file in the same working folder when the best training is found\n",
    "#         np.savetxt(\"w.txt\", self.W)\n",
    "#         np.savetxt(\"b.txt\", self.b)\n",
    "\n",
    "\n",
    "# Grid search for the number of iterations, learning rate and learning rate decay for the best accuracy\n",
    "test_label = test_label.reshape(len(test_label))  # reshape the test label\n",
    "iterations = [300, 500, 1000, 2000, 4000, 5000]\n",
    "lr = [1e-5, 5*1e-4, 1e-4, 5*1e-4, 5*1e-3, 1e-3, 5*1e-3, 1e-2, 5*1e-2, 1e-1]\n",
    "lr_decay =[0.99, 0.98, 0.97, 0.96, 0.95, 0.90]\n",
    "best_specificity_and_sensitivity = 0\n",
    "iteration_accuracy_at = 0\n",
    "pred_list = []\n",
    "for i in iterations:\n",
    "    for k in lr:\n",
    "        for n in lr_decay:\n",
    "            NN = Neural_Network() # initialize the object\n",
    "            #('training with:', i,'iterations', k, 'learning rate', n, 'learning rate decay')\n",
    "            specificity_and_sensitivity_average , pred_list = NN.train(train_set, test_set, test_label, train_label, i, k, n)\n",
    "            if specificity_and_sensitivity_average  > best_specificity_and_sensitivity:\n",
    "                best_specificity_and_sensitivity = specificity_and_sensitivity_average\n",
    "                mark_i = i\n",
    "                mark_k = k\n",
    "                mark_n = n\n",
    "                best_pred_list = pred_list\n",
    "\n",
    "print('best hyper-parameters:', mark_i, mark_k, mark_n) \n",
    "print(np.array(best_pred_list[:25]), test_label[:25])\n",
    "accuracy = np.mean(best_pred_list == test_label)\n",
    "print('accuracy', accuracy)\n",
    "tn, fp, fn, tp = confusion_matrix(test_label, best_pred_list).ravel()\n",
    "print(tn, fp, fn, tp)\n",
    "weighted_accuracy = (0.85* tn/(tn+fp) + 0.15* tp/(tp+fn))\n",
    "print(weighted_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for i =: 1 tn, fp, fn, tp values are:  428 59 55 14\n",
      "for i =: 2 tn, fp, fn, tp values are:  466 21 67 2\n",
      "for i =: 3 tn, fp, fn, tp values are:  449 38 57 12\n",
      "for i =: 4 tn, fp, fn, tp values are:  475 12 65 4\n",
      "for i =: 5 tn, fp, fn, tp values are:  466 21 60 9\n",
      "for i =: 6 tn, fp, fn, tp values are:  474 13 64 5\n",
      "for i =: 7 tn, fp, fn, tp values are:  468 19 63 6\n",
      "for i =: 8 tn, fp, fn, tp values are:  476 11 67 2\n",
      "[79.5, 84.17, 82.91, 86.15, 85.43, 86.15, 85.25, 85.97]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fbdbb934a50>]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Write a KNN to analyze the data. Then, compare it with the one layer NN above. \n",
    "\n",
    "# view the data type and shape one more time using numpy arrays.\n",
    "# print(type(test_set), test_set.shape)\n",
    "# print(type(train_set), train_set.shape)\n",
    "# print(type(test_label), test_label.shape) \n",
    "# print(type(train_label), train_label.shape)\n",
    "\n",
    "def K_Nearest_Neighbor(test_set, test_label, train_set, train_label, n): \n",
    "    results = []\n",
    "    for i in range(len(test_set)):\n",
    "        indices_visited = [] # make a list of indices visited\n",
    "        votes = np.zeros(2)\n",
    "        for j in range(n):\n",
    "            min = np.inf\n",
    "            for k in range(len(train_set)):\n",
    "                difference = np.linalg.norm(train_set[k] - test_set[i])\n",
    "                if difference < min and k not in indices_visited:\n",
    "                    min = difference\n",
    "                    index_at_min_distance = k\n",
    "                    the_label_found_at_min_dist = int(train_label[k])\n",
    "            indices_visited.append(index_at_min_distance)\n",
    "            votes[the_label_found_at_min_dist] +=1\n",
    "        label_of_max_votes = np.argmax(votes)\n",
    "        results.append(label_of_max_votes)\n",
    "    # check the accuracy by comparing predictions with the actual test labels\n",
    "    tn, fp, fn, tp = confusion_matrix(test_label, results).ravel()\n",
    "    print('for i =:', n, 'tn, fp, fn, tp values are: ' , tn, fp, fn, tp  )\n",
    "    best_score = (0.85* tn/(tn+fp) + 0.15* tp/(tp+fn))\n",
    "    accuracy = np.sum(results == test_label) / len(test_label)\n",
    "    return best_score, np.around(100*accuracy, decimals = 2) \n",
    "    \n",
    "all_results = []   \n",
    "for i in range(1,9):\n",
    "    best_scores, accuracy = K_Nearest_Neighbor(test_set, test_label, train_set, train_label, i)\n",
    "    all_results.append(accuracy)\n",
    "print(all_results)\n",
    "plt.plot(np.arange(1,9), np.array(all_results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for i =: 1 tn, fp, fn, tp values are:  428 59 55 14\n",
      "for i =: 2 tn, fp, fn, tp values are:  466 21 67 2\n",
      "for i =: 3 tn, fp, fn, tp values are:  449 38 57 12\n",
      "for i =: 4 tn, fp, fn, tp values are:  475 12 65 4\n",
      "for i =: 5 tn, fp, fn, tp values are:  466 21 60 9\n",
      "for i =: 6 tn, fp, fn, tp values are:  474 13 64 5\n",
      "for i =: 7 tn, fp, fn, tp values are:  468 19 63 6\n",
      "for i =: 8 tn, fp, fn, tp values are:  476 11 67 2\n",
      "[79.5, 84.17, 82.91, 86.15, 85.43, 86.15, 85.25, 85.97]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fbdbba5be10>]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# See if more weights is given to find the TPs, would yield a better accuracy. \n",
    "# (Don't try this at work! You might be fired even if you are right. Remember, this dataset has 85% negatives)\n",
    "\n",
    "def Tweaked_K_Nearest_Neighbor(test_set, test_label, train_set, train_label, n): \n",
    "    results = []\n",
    "    for i in range(len(test_set)):\n",
    "        indices_visited = [] # make a list of indices visited\n",
    "        votes = np.zeros(2)\n",
    "        for j in range(n):\n",
    "            min = np.inf\n",
    "            for k in range(len(train_set)):\n",
    "                difference = np.linalg.norm(train_set[k] - test_set[i])\n",
    "                if difference < min and k not in indices_visited:\n",
    "                    min = difference\n",
    "                    index_at_min_distance = k\n",
    "                    the_label_found_at_min_dist = int(train_label[k])\n",
    "            indices_visited.append(index_at_min_distance)\n",
    "            votes[the_label_found_at_min_dist] +=1\n",
    "        if votes[1] >= n//2:\n",
    "            weighted_votes = 1\n",
    "        else:\n",
    "            weighted_votes = 0\n",
    "        results.append(weighted_votes)\n",
    "    tn, fp, fn, tp = confusion_matrix(test_label, results).ravel()\n",
    "    print('for i =:', n, 'tn, fp, fn, tp values are: ' , tn, fp, fn, tp  )\n",
    "    best_score = (0.85* tn/(tn+fp) + 0.15* tp/(tp+fn))\n",
    "    accuracy = np.sum(results == test_label) / len(test_label)\n",
    "    return best_score, np.around(100*accuracy, decimals = 2) \n",
    "\n",
    "# view some of the results to judge the accuracy of this model:\n",
    "all_results = []   \n",
    "for i in range(1,9):\n",
    "    best_scores, accuracy = K_Nearest_Neighbor(test_set, test_label, train_set, train_label, i)\n",
    "    all_results.append(accuracy)\n",
    "print(all_results)\n",
    "plt.plot(np.arange(1,9), np.array(all_results))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/volkansonmez/miniconda/lib/python3.7/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8758992805755396\n",
      "[[484   3]\n",
      " [ 66   3]]\n",
      "0.8512855995000446\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Check the sklearn linear model's logistic regression classifier and compare it with the above algorithms\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "clf = LogisticRegression().fit(train_set, train_label)\n",
    "pred = clf.predict(test_set)\n",
    "# check accuracy: Accuracy = (True Pos + True Negative)\n",
    "accuracy = accuracy_score(test_label, pred)\n",
    "print(accuracy)\n",
    "cnf_matrix_log = confusion_matrix(test_label, pred)\n",
    "print(cnf_matrix_log) \n",
    "sns.heatmap(pd.DataFrame(cnf_matrix_log), annot=True,cmap=\"Reds\" , fmt='g')\n",
    "\n",
    "# conclusion: it is not a good system, sensitivity rate is very low, false negatives are high\n",
    "tn, fp, fn, tp = confusion_matrix(test_label, pred).ravel()\n",
    "weighted_accuracy = (0.85* tn/(tn+fp) + 0.15* tp/(tp+fn))\n",
    "print(weighted_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[EPOCH]: 99, [LOSS]: 0.465822, [ACCURACY]: 0.843\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/volkansonmez/miniconda/lib/python3.7/site-packages/torch/nn/modules/loss.py:529: UserWarning: Using a target size (torch.Size([3100])) that is different to the input size (torch.Size([3100, 1])) is deprecated. Please ensure they have the same size.\n",
      "  return F.binary_cross_entropy(input, target, weight=self.weight, reduction=self.reduction)\n"
     ]
    }
   ],
   "source": [
    "# BONUS: Do a simple 3 layer pytorch sequential model, train it, and test the data\n",
    "\n",
    "import numpy as np\n",
    "import random\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "import torch.functional as F\n",
    "from IPython import display\n",
    "\n",
    "y = y.reshape(-1)\n",
    "# prepare the data for torch tensors\n",
    "x = torch.from_numpy(train_set).float()\n",
    "y = torch.from_numpy(train_label).float()\n",
    "\n",
    "dtype = float\n",
    "\n",
    "D_in, H1, H2, D_out = 11, 50, 10, 1\n",
    "learning_rate = 1e-3\n",
    "\n",
    "\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(D_in, H1),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(H1, H2),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(H2, D_out),\n",
    "    nn.Sigmoid(),\n",
    ")\n",
    "\n",
    "# nn package also has different loss functions.\n",
    "criterion = torch.nn.BCELoss()\n",
    "\n",
    "# we use the optim package to apply\n",
    "# stochastic gradient descent for our parameter updates\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate) \n",
    "\n",
    "# Training\n",
    "for t in range(100):\n",
    "    \n",
    "    # Feed forward to get the logits\n",
    "    y_pred = model(x)\n",
    "    \n",
    "    # Compute the loss and accuracy\n",
    "    loss = criterion(y_pred, y)\n",
    "    score, predicted = torch.max(y_pred, 1)\n",
    "    y = y.reshape(-1)\n",
    "    acc = ((y == predicted).sum()).float() / len(x)\n",
    "    print(\"[EPOCH]: %i, [LOSS]: %.6f, [ACCURACY]: %.3f\" % (t, loss.item(), acc))\n",
    "    display.clear_output(wait=True)\n",
    "    \n",
    "    # zero the gradients before running\n",
    "    # the backward pass.\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    # Backward pass to compute the gradient\n",
    "    # of loss w.r.t our learnable params. \n",
    "    loss.backward()\n",
    "    \n",
    "    # Update params\n",
    "    optimizer.step()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "[[ go back to the top ]](#Table-of-contents)\n",
    "    \n",
    "\n",
    "KNN, Sklearn's Logistic Regression, a One layer NN, and a Three layer NN models all fail to get a good accuracy (more than 85%) since the dataset is too noisy. When all these models get trained with optimium hyperparameters the accuracy is reaching max 87% but there is too much false positives and false negatives in the confusion matrix which reveals that this dataset is too small and noisy.\n",
    "\n",
    "Keep in mind: Dataset's quality and size is directly corralated with any model's accuracy."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
